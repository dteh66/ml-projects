{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset link\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('../Datasets'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                           headline  \\\n",
      "0      1  thirtysomething scientists unveil doomsday clo...   \n",
      "1      0  dem rep. totally nails why congress is falling...   \n",
      "2      0  eat your veggies: 9 deliciously different recipes   \n",
      "3      1  inclement weather prevents liar from getting t...   \n",
      "4      1  mother comes pretty close to using word 'strea...   \n",
      "\n",
      "                                        article_link  \n",
      "0  https://www.theonion.com/thirtysomething-scien...  \n",
      "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
      "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
      "3  https://local.theonion.com/inclement-weather-p...  \n",
      "4  https://www.theonion.com/mother-comes-pretty-c...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-026d8913a6176efd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /Users/test/.cache/huggingface/datasets/json/default-026d8913a6176efd/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66be4b68891b4e78815a7fa77150f498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc63c41285c48ad92e4ca0bbde913bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ee887c22204ea2b30cc9c56bcb89ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/test/.cache/huggingface/datasets/json/default-026d8913a6176efd/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6e79c9254c42a6b6f6ba3d0d1aeaba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_v2_path = \"../Datasets/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\"\n",
    "df = pd.read_json(dataset_v2_path, lines=True)\n",
    "print(df.head())\n",
    "\n",
    "dataset_hf=load_dataset(\"json\", data_files=dataset_v2_path)\n",
    "dataset_hf=dataset_hf.remove_columns(['article_link'])\n",
    "dataset_hf.set_format('pandas')\n",
    "dataset_hf=dataset_hf['train'][:]\n",
    "dataset_hf.drop_duplicates(subset=['headline'],inplace=True)\n",
    "dataset_hf=dataset_hf.reset_index()[['headline','label']]\n",
    "dataset_hf=Dataset.from_pandas(dataset_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['headline', 'label'],\n",
      "        num_rows: 22802\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['headline', 'label'],\n",
      "        num_rows: 2851\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['headline', 'label'],\n",
      "        num_rows: 2850\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Train Test Valid Split\n",
    "train_testvalid = dataset_hf.train_test_split(test_size=0.2,seed=15)\n",
    "\n",
    "\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5,seed=15)\n",
    "\n",
    "dataset_hf = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "print(dataset_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75088cdf9d9242e98dc5f0a33fb95d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0c4e562fc64287a7af370f59129dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8df82eab884bfba5feeea95ef66a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 22802\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2851\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['headline', 'label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 2850\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#Checkpoint\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "#In the model distilbert-base-uncased\n",
    "# #each token is embedded into a vector of size 768. \n",
    "# The shape of the output from the base model is\n",
    "# (batch_size, max_sequence_length, embedding_vector_size=768)\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.model_max_len = 512\n",
    "\n",
    "def tokenize(batch):\n",
    "  return tokenizer(batch[\"headline\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset_hf.map(tokenize, batched=True)\n",
    "print(tokenized_dataset)\n",
    "tokenized_dataset.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"label\"] )\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# https://huggingface.co/docs/transformers/main_classes/data_collator\n",
    "# Data collators are objects that will form a batch by using a list of dataset elements as input. \n",
    "# These elements are of the same type as the elements of train_dataset or eval_dataset.\n",
    "# To be able to build batches, data collators may apply some processing (like padding). \n",
    "#  Some of them (like DataCollatorForLanguageModeling) also apply some random data augmentation \n",
    "# (like random masking) on the formed batch.\n",
    "# data_collator automatically pads the model inputs in a batch to the length of the longest example.\n",
    "# This bypasses the need to set a global maximum sequence length, \n",
    "# and in practice leads to faster training since we perform fewer redundant computations \n",
    "# on the padded tokens and attention masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTaskSpecificCustomModel(nn.Module):\n",
    "    def __init__(self, checkpoint, num_labels ):\n",
    "        super(MyTaskSpecificCustomModel, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        self.model = model = AutoModel.from_pretrained(checkpoint, config = AutoConfig.from_pretrained(checkpoint, \n",
    "                                                                                                       output_attention = True, \n",
    "                                                                                                       output_hidden_state = True ) )\n",
    "        # New Layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(768, num_labels )\n",
    "        \n",
    "    def forward(self, input_ids = None, attention_mask=None, labels = None ):\n",
    "        #If the attention_mask is 0, the token id is ignored. \n",
    "        # For instance if a sequence is padded to adjust the sequence length, \n",
    "        # the padded words should be ignored hence their attention_mask are 0.\n",
    "        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask  )\n",
    "        \n",
    "        last_hidden_state = outputs[0]\n",
    "        \n",
    "        sequence_outputs = self.dropout(last_hidden_state)\n",
    "        \n",
    "        logits = self.classifier(sequence_outputs[:, 0, : ].view(-1, 768 ))\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            loss = loss_func(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            \n",
    "            return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sense of nn.Linear\n",
    "In your Neural Network, the self.hidden = nn.Linear(784, 256) defines a hidden (meaning that it is in between of the input and output layers), fully connected linear layer, \n",
    "which takes input x of shape (batch_size, 784), where batch size is the number of inputs (each of size 784) which are passed to the network at once (as a single tensor), \n",
    "and transforms it by the linear equation y = x*W^T + b into a tensor y of shape (batch_size, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch Data Loader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset['train'], shuffle = True, batch_size = 32, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_dataset['valid'], shuffle = True, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/test/opt/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd958d5f13d4882b13dc3cb2fd83e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709eaef89ad14a039119132f1246c94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.909952606635071}\n",
      "{'f1': 0.9244274809160304}\n",
      "{'f1': 0.9266975308641977}\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_task_specific = MyTaskSpecificCustomModel(checkpoint=checkpoint, num_labels=2 ).to(device)\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model_task_specific.parameters(), lr = 5e-5 )\n",
    "\n",
    "num_epoch = 3\n",
    "\n",
    "num_training_steps = num_epoch * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps,\n",
    "    \n",
    ")\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "progress_bar_eval = tqdm(range(num_epoch * len(eval_dataloader) ))\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    model_task_specific.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        #print(batch)\n",
    "        outputs = model_task_specific(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar_train.update(1)\n",
    "        \n",
    "    model_task_specific.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        with torch.no_grad():\n",
    "            outputs = model_task_specific(**batch)\n",
    "            \n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim = -1 )\n",
    "        metric.add_batch(predictions = predictions, references = batch['labels'] )\n",
    "        progress_bar_eval.update(1)\n",
    "        \n",
    "    print(metric.compute()) \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bad inputs for metric: ['predictons']. All required inputs are ['predictions', 'references']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-70899ec35953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#metric.add_batch(predictons = predictions, references=batch['labels'] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/datasets/metric.py\u001b[0m in \u001b[0;36madd_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mbad_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbad_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bad inputs for metric: {bad_inputs}. All required inputs are {list(self.features)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"references\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mintput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mintput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Bad inputs for metric: ['predictons']. All required inputs are ['predictions', 'references']"
     ]
    }
   ],
   "source": [
    "#Post training evaluation\n",
    "model_task_specific.eval()\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset['test'], batch_size = 32, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = { k: v.to(device) for k, v in batch.items() }\n",
    "    with torch.no_grad():\n",
    "        outputs = model_task_specific(**batch)\n",
    "        \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim = -1)\n",
    "    #metric.add_batch(predictons = predictions, references=batch['labels'] )\n",
    "    metric.add_batch(predictons = predictions, references=batch['labels'] )\n",
    "    \n",
    "metric.compute()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "521bf23a49300457a383cc0ce4a9a5b8cdf2cad9d8aaec6ddd3bd1c99845bf26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
