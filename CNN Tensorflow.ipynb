{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32f04bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "#Dense RNN or CNN ends fully connected layer\n",
    "#import model\n",
    "import time\n",
    "import pickle\n",
    "x = pickle.load(open(\"x.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#normalize data -> scale\n",
    "x = x/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d4eb004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-64-nodes-0-dense-1672696371\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 52s 72ms/step - loss: 0.6414 - accuracy: 0.6217 - val_loss: 0.5885 - val_accuracy: 0.6866\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 49s 70ms/step - loss: 0.5414 - accuracy: 0.7284 - val_loss: 0.5314 - val_accuracy: 0.7423\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 50s 71ms/step - loss: 0.4944 - accuracy: 0.7603 - val_loss: 0.5167 - val_accuracy: 0.7447\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 49s 70ms/step - loss: 0.4588 - accuracy: 0.7867 - val_loss: 0.4677 - val_accuracy: 0.7816\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 48s 69ms/step - loss: 0.4296 - accuracy: 0.8011 - val_loss: 0.4796 - val_accuracy: 0.7727\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 53s 75ms/step - loss: 0.3995 - accuracy: 0.8180 - val_loss: 0.4564 - val_accuracy: 0.7952\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 52s 75ms/step - loss: 0.3726 - accuracy: 0.8344 - val_loss: 0.4285 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 52s 74ms/step - loss: 0.3477 - accuracy: 0.8469 - val_loss: 0.4462 - val_accuracy: 0.8000\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 49s 70ms/step - loss: 0.3274 - accuracy: 0.8548 - val_loss: 0.4297 - val_accuracy: 0.8004\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 52s 74ms/step - loss: 0.3047 - accuracy: 0.8661 - val_loss: 0.4278 - val_accuracy: 0.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 64x3-CNN.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 64x3-CNN.model/assets\n"
     ]
    }
   ],
   "source": [
    "#NAME = \"Cats-vs-dog-cnn-64x2-{}\".format(int(time.time()))\n",
    "#logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#tensorboard = TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "# logdir = \"logs/text_basics/\" + time.time()\n",
    "# Creates a file writer for the log directory.\n",
    "# file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Using the file writer, log the text.\n",
    "# with file_writer.as_default():\n",
    "\n",
    "#Deciding best model\n",
    "#Easy: Number of Layers, Nodes per layer, dense layer at end or not\n",
    "dense_layers = [0] #1, 2\n",
    "#dense_layer_size = [512]\n",
    "layer_sizes = [64] #conv layer 32, 128\n",
    "conv_layers = [3] #1, 2\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            print(NAME)\n",
    "            model = Sequential()\n",
    "            #CNN layer, convert 2d image into a new 2D dot product image\n",
    "            #3x3 size kernel\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape = x.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            #then, a pooling window, where takes max of 2x2 sliding square\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "            for l in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            #third layer, to convert image into 1d array\n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size)) #dense_layer_size\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(Dropout(0.2)) #anti-overfitting\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            model.compile(loss=\"binary_crossentropy\", \n",
    "                        optimizer=\"adam\",\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "            model.fit(x, y, batch_size=32, epochs=10, validation_split=0.1, callbacks = [tensorboard])\n",
    "\n",
    "model.save('64x3-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f275a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "Dog\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Cat\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3-CNN.model\")\n",
    "prediction = model.predict([prepare('Datasets/cat.jpg')])\n",
    "#prediction = model.predict([prepare('dog.jpg')])\n",
    "print(CATEGORIES[int(prediction[0][0])])\n",
    "prediction = model.predict([prepare('Datasets/cat2.jpg')])\n",
    "print(CATEGORIES[int(prediction[0][0])])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "521bf23a49300457a383cc0ce4a9a5b8cdf2cad9d8aaec6ddd3bd1c99845bf26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
